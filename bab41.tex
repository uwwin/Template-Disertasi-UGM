\chapter{METODOLOGI PENELITIAN}


\section{Studi Literatur}
Studi literatur dilakukan dengan mempelajari penelitian sebelumnya yang terkait yang diperoleh dari berbagai macam sumber seperti buku, artikel, publikasi jurnal, paper, tesis, disertasi dll. Alur secara urut dari penelitian ini sepert pada Gambar \ref{fig:metodologiFL}


\begin{figure}
    \centering
\includegraphics[width=0.75\linewidth]{figures/metodologi_fl.png}
    \caption{Alur Penelitian}
    \label{fig:metodologiFL}
\end{figure}

\section{Alat dan Bahan}
\subsection{Alat}
Alat yang digunakan dalam penelitian ini yaitu:
\begin{enumerate}
    \item Python  versi 3.3 untuk Windows 64 bit.
    \item Server Intel Xeon® E5-2680 v4 3.30GHz GPU Nvidia RTX 3060 RAM 32
    \item Server Intel Xeon® 2.00GHz GPU Nvidia Tesla T4 RAM 12
    \item Server Intel Xeon® E5-2680 v3 3.30GHz GPU Nvidia RTX 2080 Ti RAM 32
    \item Server AMD Ryzen 9 3950X 3.50GHz GPU Nvidia Tesla A2000 RAM 64
\end{enumerate}
\subsection{Bahan}
Bahan yang digunakn dalam penelitan ini adalah dataset gambar dan dataset tabular. Dataset gambar tersebut adalah HAM10000 dan ISIC2019, sedangkan dataset tabular yang digunakan adalah .
\section{Pengambilan Data}
Data diambil dari dataset public yang ada di internet dengan rincin sepeti Tabel \ref{tab:Dataset}

\begin{table}[]
\centering
\caption{Rekapitulasi Dataset}
\label{tab:Dataset}
\begin{tabular}{|c|c|c|}
\hline
\textbf{No} & \textbf{Nama Dataset} & \textbf{Jumlah} \\
\hline
1 & HAM10000 (Tschandl, n.d.) & 10.015 \\
\hline
2 & PAD-UFES (Pacheco et al., 2020) & 2.298 \\
\hline
3 & ISIC19 (Combalia et al., 2019) & 25.331 \\
\hline
4 & Derm7pt (Kawahara et al., 2019) & 1.011 \\
\hline
\textbf{Total} & & \textbf{38.655} \\
\hline
\end{tabular}
\end{table}


\section{Prosedur Kerja}
\subsection{Analisis dan Perancangan Sistem}
Dalam analisis ini akan dibahas mengenai dataset. Dataset yang digunakan merupakan gabungan dari empat dataset diantaranya  yang pertama HAM10000 yaitu dataset terdiri dari 10.015 data citra dermatoskopi untuk lesi kulit berpigmen yang umum, termasuk penyakit bowen, karsinoma sel basal, dermatofibroma, melanoma, melanocytic nevi, dan lesi vaskular. Data gambar dalam dataset telah divalidasi melalui histopatologi, pemeriksaan tambahan, konsensus pakar, dan konfirmasi in-vivo confocal microscopy. Dataset kedua adalah PAD-UFES merupakan dataset yang dibangun dengan menggunakan telepon genggam oleh University Federated Espírito Santo. Dataset ini terdiri dari 6 kelas yang telah divalidasi sesuai prosedur hispatologi. Dataset ketiga adalah ISIC19 merupakan dataset yang terdiri dari 8 kelas dataset. Dataset keempat yaitu Derm7pt merupakan salah satu dataset yang dibuat oleh.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/datasetKulit.png}
    \caption{Dataset Lesi Kulit}
    \label{fig:datasetLesiKulit}
\end{figure}

Dataset yang digunakan dalam penelitian ini telah melewati proses pembersihan dan pra-pemrosesan awal. Oleh karena itu, tidak perlu ada langkah tambahan dalam proses pra-pemrosesan data sebelum digunakan dalam eksperimen. Namun, karena ukuran setiap citra bervariasi, setiap gambar akan disesuaikan menjadi 150 piksel menggunakan OpenCV.

\section{Implementasi}




\subsection{Agregasi Model}
Dalam proses pengumpulan model pada dataset IID umumnya digunakan FedAvg. Mekanisme FedAvg yang memiliki data yang mirip diantara klien sangat sulit ditemukan dalam praktik dunia nyata. Pada umumnya data antara klien atau instansi itu berbeda-beda. Ide dasar itu yang menginspirasi proses agregasi. 

Dalam format persamaan agregasi bobot global:
\[
w^{(t)} = \sum_{k=1}^{K} \frac{N_k}{N} \cdot w_k^{(t)}
\]
dimulai dari prinsip dasar gradient descent dan federated learning. Penurunan ini mengikuti urutan: update lokal, definisi loss global, dan substitusi ke dalam update global.

1. Update Lokal oleh Client ke-$k$

Setiap client $k$ memulai dari bobot global sebelumnya $w^{(t-1)}$ dan melakukan satu langkah \textit{gradient descent} terhadap loss lokalnya $L_k(w)$:

\[
w_k^{(t)} = w^{(t-1)} - \alpha \cdot \nabla L_k(w^{(t-1)})
\]

\begin{itemize}
    \item $w_k^{(t)}$: bobot lokal client $k$ setelah update pada iterasi $t$
    \item $\alpha$: \textit{learning rate}
    \item $\nabla L_k(w^{(t-1)})$: gradien dari loss lokal client $k$
\end{itemize}

 2. Definisi Update Bobot Global dari Loss Global
 
Dalam federated learning, bobot global mengikuti langkah gradient descent terhadap loss global $L_{\text{global}}(w)$:

\[
w^{(t)} = w^{(t-1)} - \alpha \cdot \nabla L_{\text{global}}(w^{(t-1)})
\]

Dengan gradien loss global dihitung sebagai:

\[
\nabla L_{\text{global}}(w^{(t-1)}) = \sum_{k=1}^{K} \frac{N_k}{N} \cdot \nabla L_k(w^{(t-1)})
\]

\begin{itemize}
    \item $N_k$: jumlah data pada client $k$
    \item $N = \sum_{k=1}^{K} N_k$: total data dari semua client
\end{itemize}

3. Substitusi ke dalam Update Bobot Global

Substitusikan ekspresi gradien global ke dalam update global:

\[
\begin{aligned}
w^{(t)} 
&= w^{(t-1)} - \alpha \cdot \sum_{k=1}^{K} \frac{N_k}{N} \cdot \nabla L_k(w^{(t-1)}) \\
&= \sum_{k=1}^{K} \frac{N_k}{N} \cdot \left(w^{(t-1)} - \alpha \cdot \nabla L_k(w^{(t-1)}) \right)
\end{aligned}
\]

Kemudian gunakan kembali bentuk update lokal $w_k^{(t)}$:

\[
w_k^{(t)} = w^{(t-1)} - \alpha \cdot \nabla L_k(w^{(t-1)})
\]

Sehingga:

\[
w^{(t)} = \sum_{k=1}^{K} \frac{N_k}{N} \cdot w_k^{(t)}
\]

4. Intuisi di Balik Agregasi

\begin{itemize}
    \item Semua client memulai dari bobot global yang sama $w^{(t-1)}$
    \item Setiap client melakukan update berdasarkan datanya sendiri
    \item Server cukup mengumpulkan bobot lokal dari masing-masing client
    \item Server menggabungkan dengan rata-rata tertimbang berdasarkan jumlah data masing-masing client
\end{itemize}
Persamaan agregasi bobot global yang digunakan dalam algoritma Federated Averaging (FedAvg) adalah:

\[
w^{(t)} = \sum_{k=1}^{K} \frac{N_k}{N} \cdot w_k^{(t)}
\]

yang diturunkan dari:

\begin{itemize}
    \item Update lokal: $w_k^{(t)} = w^{(t-1)} - \alpha \cdot \nabla L_k(w^{(t-1)})$
    \item Gradien loss global: $\nabla L_{\text{global}}(w) = \sum_{k=1}^{K} \frac{N_k}{N} \cdot \nabla L_k(w)$
    \item Substitusi gradien ke dalam update descent global
\end{itemize}




\subsection{Optimasi}
 Dalam proses  mekanisme strategy agregasi yang tepat untuk mendapatkan hasil performa yang terbaik.
Untuk mendapatkan performa yang terbaik akan digunakan algoritma metaheuristic sudah terbukti memiliki kemampuan untuk mencari solusi optimum. Diantara algoritma metaheuristic yang dikenal  Algoritma Genetik (AG), Grey Wolf Optimization (GWO),  Whale Optimization Algorithm (WOA) dan lain-lain. GWO merupakan salah satu algoritma yang terkenal dengan cepat menemukan solusi. Namun GWO memiliki kekurangan seringkali terjebak dalam local minima. AG merupakan salah satu algoritma yang mampu keluar dari masalah local minima, namun waktunya relatif lebih panjang. Salah satunya dalam AG digunakan ide dari AG yaitu mutasi  dan \textit{crossover} sebagai salah satu solusi agar GWO tidak terjebak dalam local minima. Usulan kombinasi GWO dengan AG dapat dilihat seperti Algoritma \ref{alg:GWOGA}






objective function dalam penentuan bobot kasus non IID Federated Learning dapat digambarkan sebagai Algoritma 





